#!/usr/bin/env python3
"""
Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö SPNet –∏ STECCOM
–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–º —Ñ–∞–π–ª–æ–≤ –≤ Oracle (production)
"""

import streamlit as st
import pandas as pd
from pathlib import Path
import os
import glob
from datetime import datetime
import subprocess
import sys

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Oracle
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø–∞—Ä–æ–ª–µ–π –≤ production!
ORACLE_CONFIG = {
    'username': os.getenv('ORACLE_USER', 'billing7'),
    'password': os.getenv('ORACLE_PASSWORD', 'your-password-here'),
    'host': os.getenv('ORACLE_HOST', 'your-oracle-host'),
    'port': int(os.getenv('ORACLE_PORT', '1521')),
    'service_name': os.getenv('ORACLE_SERVICE', 'bm7')
}

DATA_DIR = Path(__file__).parent / 'data'
SPNET_DIR = DATA_DIR / 'SPNet reports'
STECCOM_DIR = DATA_DIR / 'STECCOMLLCRussiaSBD.AccessFees_reports'


def get_db_connection():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö Oracle"""
    try:
        import cx_Oracle
        conn = cx_Oracle.connect(
            ORACLE_CONFIG['username'],
            ORACLE_CONFIG['password'],
            f"{ORACLE_CONFIG['host']}:{ORACLE_CONFIG['port']}/{ORACLE_CONFIG['service_name']}"
        )
        return conn
    except ImportError:
        st.error("cx_Oracle –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install cx_Oracle")
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Oracle: {e}")
        return None


def get_loaded_files_info(table_name, source_file_column='SOURCE_FILE'):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö"""
    conn = get_db_connection()
    if not conn:
        return pd.DataFrame()
    
    try:
        # Oracle —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
        query = f"""
        SELECT DISTINCT 
            {source_file_column} AS file_name,
            MAX(LOAD_DATE) AS last_load_date,
            COUNT(*) AS records_count
        FROM {table_name}
        WHERE {source_file_column} IS NOT NULL
        GROUP BY {source_file_column}
        ORDER BY MAX(LOAD_DATE) DESC
        FETCH FIRST 20 ROWS ONLY
        """
        df = pd.read_sql(query, conn)
        return df
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö: {e}")
        return pd.DataFrame()
    finally:
        conn.close()


def get_records_in_db(file_name, table_name='SPNET_TRAFFIC', conn=None):
    """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    
    Args:
        file_name: –∏–º—è —Ñ–∞–π–ª–∞
        table_name: –∏–º—è —Ç–∞–±–ª–∏—Ü—ã (Oracle, uppercase)
        conn: —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ - —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤–æ–µ)
    """
    should_close = False
    if conn is None:
        conn = get_db_connection()
        if not conn:
            return None
        should_close = True
    
    try:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT COUNT(*) FROM {} 
            WHERE UPPER(SOURCE_FILE) = UPPER(:1)
        """.format(table_name), (file_name,))
        count = cursor.fetchone()[0]
        cursor.close()
        return count
    except Exception as e:
        return None
    finally:
        if should_close and conn:
            conn.close()


def count_file_records(file_path):
    """–ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ (CSV –∏–ª–∏ XLSX)"""
    try:
        import pandas as pd
        file_ext = Path(file_path).suffix.lower()
        
        if not Path(file_path).exists():
            return None
        
        if file_ext == '.xlsx':
            try:
                df = pd.read_excel(file_path, dtype=str, na_filter=False, engine='openpyxl')
                # –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                df = df.dropna(how='all')
                # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—É—Å—Ç—ã–µ –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã
                df = df[~df.apply(lambda x: x.astype(str).str.strip().eq('').all(), axis=1)]
                return len(df)
            except Exception as e:
                # –ü—Ä–æ–±—É–µ–º –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –¥–≤–∏–∂–∫–∞
                try:
                    df = pd.read_excel(file_path, dtype=str, na_filter=False)
                    df = df.dropna(how='all')
                    return len(df)
                except:
                    return None
        else:
            # CSV —Ñ–∞–π–ª
            try:
                df = pd.read_csv(file_path, dtype=str, na_filter=False, quotechar='"')
                return len(df)
            except Exception as e:
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                for encoding in ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']:
                    try:
                        df = pd.read_csv(file_path, dtype=str, na_filter=False, encoding=encoding, quotechar='"')
                        return len(df)
                    except:
                        continue
                return None
    except Exception as e:
        return None  # –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å


def list_data_files(directory):
    """–°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –ø–æ–¥—Å—á–µ—Ç–æ–º –∑–∞–ø–∏—Å–µ–π"""
    if not directory.exists():
        return []
    files = []
    for f in directory.iterdir():
        if f.is_file() and f.suffix.lower() in ['.csv', '.xlsx']:
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª–µ
            try:
                record_count = count_file_records(f)
            except Exception as e:
                # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ, –≤—Å–µ —Ä–∞–≤–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
                record_count = None
            
            files.append({
                'name': f.name,
                'size': f.stat().st_size,
                'modified': datetime.fromtimestamp(f.stat().st_mtime),
                'path': str(f),
                'records': record_count  # –ú–æ–∂–µ—Ç –±—ã—Ç—å None, int –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
            })
    return sorted(files, key=lambda x: x['modified'], reverse=True)


def run_import_script(script_name):
    """–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –∏–º–ø–æ—Ä—Ç–∞ Oracle"""
    import importlib.util
    
    scripts_dir = Path(__file__).parent / 'python'
    
    # Oracle —Å–∫—Ä–∏–ø—Ç—ã
    if script_name == 'spnet':
        script_path = scripts_dir / 'load_spnet_traffic.py'
        module_name = "load_spnet_traffic"
        class_name = "SPNetDataLoader"
        method_name = "load_spnet_files"
        config = ORACLE_CONFIG
        connect_method = "connect_to_oracle"
    elif script_name == 'steccom':
        script_path = scripts_dir / 'load_steccom_expenses.py'
        module_name = "load_steccom_expenses"
        class_name = "STECCOMDataLoader"
        method_name = "load_steccom_files"
        config = ORACLE_CONFIG
        connect_method = "connect_to_oracle"
    else:
        return False, "Unknown script type"
    
    if not script_path.exists():
        return False, f"Script not found: {script_path}"
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥—É–ª—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
        spec = importlib.util.spec_from_file_location(module_name, script_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∑–∞–≥—Ä—É–∑—á–∏–∫–∞
        loader_class = getattr(module, class_name)
        loader = loader_class(config)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
        loader.gdrive_path = str(SPNET_DIR if script_name == 'spnet' else STECCOM_DIR)
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        connect_func = getattr(loader, connect_method)
        if not connect_func():
            return False, "Failed to connect to Oracle database"
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
        import io
        from contextlib import redirect_stdout, redirect_stderr
        
        log_capture = io.StringIO()
        try:
            with redirect_stdout(log_capture), redirect_stderr(log_capture):
                method = getattr(loader, method_name)
                result = method()
            
            log_output = log_capture.getvalue()
            
            if loader.connection:
                loader.connection.close()
            
            if result:
                return True, log_output if log_output else "Import completed successfully"
            else:
                return False, log_output if log_output else "Import failed"
        finally:
            if hasattr(loader, 'connection') and loader.connection:
                loader.connection.close()
            
    except Exception as e:
        import traceback
        return False, f"Error: {str(e)}\n{traceback.format_exc()}"


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    st.set_page_config(
        page_title="Data Loader - Iridium M2M",
        page_icon="üì•",
        layout="wide"
    )
    
    st.title("üì• Data Loader - Iridium M2M")
    st.markdown("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö SPNet –∏ STECCOM –≤ Oracle (production)")
    st.markdown("---")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Oracle –≤ —Å–∞–π–¥–±–∞—Ä–µ
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è Oracle Configuration")
        oracle_host = st.text_input("Host", value=ORACLE_CONFIG['host'], key='oracle_host')
        oracle_port = st.number_input("Port", value=ORACLE_CONFIG['port'], key='oracle_port')
        oracle_service = st.text_input("Service Name", value=ORACLE_CONFIG['service_name'], key='oracle_service')
        oracle_user = st.text_input("Username", value=ORACLE_CONFIG['username'], key='oracle_user')
        oracle_pass = st.text_input("Password", type="password", value=ORACLE_CONFIG['password'], key='oracle_pass')
        
        if st.button("üîÑ Update Oracle Config", key='update_oracle_btn'):
            ORACLE_CONFIG.update({
                'host': oracle_host,
                'port': int(oracle_port),
                'service_name': oracle_service,
                'username': oracle_user,
                'password': oracle_pass
            })
            st.success("Oracle configuration updated!")
        
        st.markdown("---")
        st.caption("üì° Database: **ORACLE**")
        
        # –ö–Ω–æ–ø–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –≤ sidebar (—Ç–æ–ª—å–∫–æ –∫–Ω–æ–ø–∫–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –∫–æ–Ω—Ç–µ–Ω—Ç–µ)
        st.markdown("---")
        st.markdown("### üîÑ Import All Files")
        import_clicked = st.button("üì• Import All Files (SPNet + Access Fees)", use_container_width=True, type="primary", key='import_all_files_btn')
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–º–ø–æ—Ä—Ç–∞
    if import_clicked:
        st.markdown("---")
        st.subheader("üîÑ Import Results")
        all_logs = []
        
        # –ò–º–ø–æ—Ä—Ç SPNet
        with st.spinner("–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö SPNet –≤ Oracle..."):
            success, message = run_import_script('spnet')
            all_logs.append(("SPNet", success, message))
        
        # –ò–º–ø–æ—Ä—Ç Access Fees
        with st.spinner("–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö Access Fees –≤ Oracle..."):
            success, message = run_import_script('steccom')
            all_logs.append(("Access Fees", success, message))
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        for file_type, success, message in all_logs:
            st.markdown(f"### {file_type}")
            if success:
                st.success(f"‚úÖ –ò–º–ø–æ—Ä—Ç {file_type} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                
                # –ü–∞—Ä—Å–∏–º –ª–æ–≥–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                if message:
                    import re
                    # –ò—â–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
                    records_match = re.search(r'–í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ:\s*([\d,]+)\s*–∑–∞–ø–∏—Å–µ–π', message, re.IGNORECASE)
                    if records_match:
                        records_count = records_match.group(1).replace(',', '')
                        st.metric("üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π", f"{int(records_count):,}")
                    
                    # –ò—â–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                    skipped_match = re.search(r'–ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤.*?(\d+)', message, re.IGNORECASE)
                    if skipped_match:
                        skipped_count = skipped_match.group(1)
                        st.metric("‚è≠ –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤", skipped_count)
                    
                    # –ò—â–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                    duration_match = re.search(r'–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:\s*([\d.]+)\s*—Å–µ–∫', message, re.IGNORECASE)
                    if duration_match:
                        duration = duration_match.group(1)
                        st.metric("‚è± –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", f"{float(duration):.2f} —Å–µ–∫")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ª–æ–≥–∏
                    with st.expander(f"üìã –î–µ—Ç–∞–ª—å–Ω—ã–µ –ª–æ–≥–∏ {file_type}"):
                        st.text_area("", message, height=200, key=f'log_{file_type.lower().replace(" ", "_")}')
            else:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ {file_type}")
                if message:
                    st.text_area(f"{file_type} Log", message, height=200, key=f'log_{file_type.lower().replace(" ", "_")}')
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
        st.markdown("---")
        st.info("üí° **–û–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏–ª–∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É 'üìä SPNet Traffic' / 'üí∞ Access Fees (Financial)' —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.**")
        st.markdown("---")
    
    # –¢–∞–±—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    tab1, tab2, tab3 = st.tabs([
        "üìä SPNet Traffic", 
        "üí∞ Access Fees (Financial)",
        "üìã Load History"
    ])
    
    # ========== SPNet Traffic Tab ==========
    with tab1:
        st.subheader("SPNet Traffic Reports")
        st.markdown("**–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è:** `data/SPNet reports/`")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
            spnet_files = list_data_files(SPNET_DIR)
            
            if spnet_files:
                st.markdown(f"**–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(spnet_files)}**")
                
                files_df = pd.DataFrame(spnet_files)
                
                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ records —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                if 'records' not in files_df.columns:
                    files_df['records'] = None
                
                # –ó–∞–ø–æ–ª–Ω—è–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è–º–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
                files_df['records'] = files_df['records'].fillna(None)
                
                files_df['size_mb'] = files_df['size'] / (1024 * 1024)
                files_df['modified'] = files_df['modified'].dt.strftime('%Y-%m-%d %H:%M:%S')
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                def format_records(x):
                    if x is None:
                        return "‚è≥ Calculating..."
                    try:
                        if pd.isna(x):
                            return "‚è≥ Calculating..."
                        return f"{int(x):,}"
                    except (ValueError, TypeError):
                        return "N/A"
                
                files_df['records'] = files_df['records'].apply(format_records)
                
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ (–æ–¥–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö)
                records_in_db_list = []
                conn_check = get_db_connection()
                if conn_check:
                    try:
                        for _, row in files_df.iterrows():
                            file_name = row['name']
                            try:
                                records_in_db = get_records_in_db(file_name, 'SPNET_TRAFFIC', conn=conn_check)
                                records_in_db_list.append(f"{records_in_db:,}" if records_in_db is not None and records_in_db > 0 else "-")
                            except:
                                records_in_db_list.append("-")
                    finally:
                        conn_check.close()
                else:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º "-" –¥–ª—è –≤—Å–µ—Ö
                    records_in_db_list = ["-"] * len(files_df)
                
                # –°–æ–∑–¥–∞–µ–º display_df —Å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
                display_df = pd.DataFrame()
                display_df['File Name'] = files_df['name']
                display_df['Size (MB)'] = files_df['size_mb'].round(2)
                display_df['Records in File'] = files_df['records']
                display_df['Records in DB'] = records_in_db_list
                display_df['Modified'] = files_df['modified']
                
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    hide_index=True,
                    height=300,
                    key='spnet_files_df'
                )
            else:
                st.info("üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", icon="üìÅ")
        
        with col2:
            st.markdown("### –î–µ–π—Å—Ç–≤–∏—è")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
            uploaded_file = st.file_uploader(
                "Upload SPNet file",
                type=['csv', 'xlsx'],
                key='spnet_upload'
            )
            
            if uploaded_file:
                save_path = SPNET_DIR / uploaded_file.name
                if save_path.exists():
                    st.warning(f"‚ö†Ô∏è –§–∞–π–ª `{uploaded_file.name}` —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                else:
                    if st.button("üíæ Save File", key='save_spnet'):
                        try:
                            SPNET_DIR.mkdir(parents=True, exist_ok=True)
                            with open(save_path, 'wb') as f:
                                f.write(uploaded_file.getbuffer())
                            st.success(f"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {uploaded_file.name}")
                            st.rerun()
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            
            st.markdown("---")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
            already_loaded = []
            new_files = []
            orphaned_logs = []  # –§–∞–π–ª—ã —Å –∑–∞–ø–∏—Å—å—é –≤ load_logs, –Ω–æ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ
            files_to_reload = []  # –§–∞–π–ª—ã, –≥–¥–µ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ –º–µ–Ω—å—à–µ, —á–µ–º –≤ —Ñ–∞–π–ª–µ
            if spnet_files:
                conn = get_db_connection()
                if conn:
                    try:
                        for file_info in spnet_files:
                            file_name = file_info['name']
                            records_in_file = file_info.get('records')  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ
                            has_log_entry = False
                            has_data = False
                            records_in_db = 0
                            
                            # Oracle - –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
                            cursor = conn.cursor()
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–æ–π —Å—Ç–æ–ª–±–µ—Ü –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
                            try:
                                test_query = "SELECT FILE_NAME FROM LOAD_LOGS WHERE ROWNUM = 1"
                                cursor.execute(test_query)
                                file_col = "FILE_NAME"
                            except:
                                try:
                                    test_query = "SELECT SOURCE_FILE FROM LOAD_LOGS WHERE ROWNUM = 1"
                                    cursor.execute(test_query)
                                    file_col = "SOURCE_FILE"
                                except:
                                    file_col = "FILE_NAME"  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º load_logs
                            cursor.execute(f"""
                                SELECT COUNT(*) FROM LOAD_LOGS 
                                WHERE UPPER({file_col}) = UPPER(:1) 
                                AND UPPER(TABLE_NAME) = 'SPNET_TRAFFIC'
                                AND LOAD_STATUS = 'SUCCESS'
                            """, (file_name,))
                            has_log_entry = cursor.fetchone()[0] > 0
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                            cursor.execute("""
                                SELECT COUNT(*) FROM SPNET_TRAFFIC 
                                WHERE UPPER(SOURCE_FILE) = UPPER(:1)
                            """, (file_name,))
                            records_in_db = cursor.fetchone()[0]
                            has_data = records_in_db > 0
                            cursor.close()
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π
                            if has_log_entry and has_data:
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –∑–∞–ø–∏—Å–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
                                if records_in_file is not None and records_in_file > 0:
                                    if records_in_db < records_in_file:
                                        # –í –±–∞–∑–µ –º–µ–Ω—å—à–µ –∑–∞–ø–∏—Å–µ–π, —á–µ–º –≤ —Ñ–∞–π–ª–µ - –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å
                                        files_to_reload.append((file_name, records_in_file, records_in_db))
                                        new_files.append(file_name)
                                    else:
                                        # –í—Å–µ –∑–∞–ø–∏—Å–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
                                        already_loaded.append(file_name)
                                else:
                                    # –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Å—á–∏—Ç–∞—Ç—å –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª–µ, –Ω–æ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å - —Å—á–∏—Ç–∞–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º
                                    already_loaded.append(file_name)
                            elif has_log_entry and not has_data:
                                # –û—à–∏–±–æ—á–Ω–∞—è –∑–∞–ø–∏—Å—å –≤ load_logs –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ
                                orphaned_logs.append(file_name)
                                new_files.append(file_name)  # –†–∞–∑—Ä–µ—à–∞–µ–º –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫—É
                            else:
                                new_files.append(file_name)
                    except Exception as e:
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {e}")
                    finally:
                        conn.close()
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—É—Å–µ —Ñ–∞–π–ª–æ–≤
            if orphaned_logs:
                st.error(f"‚ö†Ô∏è **–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è:** {len(orphaned_logs)} —Ñ–∞–π–ª(–æ–≤) –∏–º–µ—é—Ç –∑–∞–ø–∏—Å—å –≤ –ª–æ–≥–∞—Ö, –Ω–æ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ –Ω–µ—Ç:")
                for orphan in orphaned_logs[:5]:
                    st.text(f"  - {orphan}")
                if len(orphaned_logs) > 5:
                    st.caption(f"  ... –∏ –µ—â–µ {len(orphaned_logs) - 5} —Ñ–∞–π–ª(–æ–≤)")
                st.info("üí° –≠—Ç–∏ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞–Ω–æ–≤–æ, —á—Ç–æ–±—ã –∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ.")
            
            if files_to_reload:
                st.warning(f"‚ö†Ô∏è **–ù–µ–ø–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞:** {len(files_to_reload)} —Ñ–∞–π–ª(–æ–≤) –∏–º–µ—é—Ç –º–µ–Ω—å—à–µ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ, —á–µ–º –≤ —Ñ–∞–π–ª–µ:")
                for file_name, in_file, in_db in files_to_reload[:5]:
                    st.text(f"  - {file_name}: {in_file:,} –≤ —Ñ–∞–π–ª–µ ‚Üí {in_db:,} –≤ –±–∞–∑–µ (–Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç {in_file - in_db:,})")
                if len(files_to_reload) > 5:
                    st.caption(f"  ... –∏ –µ—â–µ {len(files_to_reload) - 5} —Ñ–∞–π–ª(–æ–≤)")
                st.info("üí° –≠—Ç–∏ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞–Ω–æ–≤–æ, —á—Ç–æ–±—ã –¥–æ–ø–æ–ª–Ω–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–∞–ø–∏—Å–∏.")
            
            if already_loaded:
                if len(already_loaded) == len(spnet_files) and not orphaned_logs and not files_to_reload:
                    st.success(f"‚úÖ **–í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é!** –ó–∞–≥—Ä—É–∂–∞—Ç—å –Ω–µ—á–µ–≥–æ.")
                    st.info(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(already_loaded)}")
                else:
                    st.info(f"‚úÖ {len(already_loaded)} –∏–∑ {len(spnet_files)} —Ñ–∞–π–ª(–æ–≤) –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã:\n- " + "\n- ".join(already_loaded[:5]))
                    if len(already_loaded) > 5:
                        st.caption(f"... –∏ –µ—â–µ {len(already_loaded) - 5} —Ñ–∞–π–ª(–æ–≤)")
                    if new_files:
                        st.info(f"üì• –ë—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–æ–≤—ã—Ö/–Ω–µ–ø–æ–ª–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(new_files)}")
            
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
        st.markdown("---")
        st.subheader("üìä –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –≤ –±–∞–∑—É —Ñ–∞–π–ª—ã")
        loaded_spnet = get_loaded_files_info('SPNET_TRAFFIC', 'SOURCE_FILE')
        if not loaded_spnet.empty:
            loaded_spnet.columns = ['File Name', 'Last Load Date', 'Records Count']
            st.dataframe(loaded_spnet, use_container_width=True, hide_index=True, key='loaded_spnet_df')
        else:
            st.info("–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö", icon="‚ÑπÔ∏è")
    
    # ========== Access Fees (Financial) Tab ==========
    with tab2:
        
        st.subheader("Access Fees Reports (Financial Files)")
        st.markdown("**–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è:** `data/STECCOMLLCRussiaSBD.AccessFees_reports/`")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
            access_fees_files = list_data_files(STECCOM_DIR)
            
            if access_fees_files:
                st.markdown(f"**–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(access_fees_files)}**")
                
                files_df = pd.DataFrame(access_fees_files)
                
                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ records —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                if 'records' not in files_df.columns:
                    files_df['records'] = None
                
                # –ó–∞–ø–æ–ª–Ω—è–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è–º–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
                files_df['records'] = files_df['records'].fillna(None)
                
                files_df['size_mb'] = files_df['size'] / (1024 * 1024)
                files_df['modified'] = files_df['modified'].dt.strftime('%Y-%m-%d %H:%M:%S')
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                def format_records(x):
                    if x is None:
                        return "‚è≥ Calculating..."
                    try:
                        import pandas as pd
                        if pd.isna(x):
                            return "‚è≥ Calculating..."
                        return f"{int(x):,}"
                    except (ValueError, TypeError):
                        return "N/A"
                
                files_df['records'] = files_df['records'].apply(format_records)
                
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ (–æ–¥–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö)
                records_in_db_list = []
                conn_check = get_db_connection()
                if conn_check:
                    try:
                        for _, row in files_df.iterrows():
                            file_name = row['name']
                            try:
                                records_in_db = get_records_in_db(file_name, 'STECCOM_EXPENSES', conn=conn_check)
                                records_in_db_list.append(f"{records_in_db:,}" if records_in_db is not None and records_in_db > 0 else "-")
                            except:
                                records_in_db_list.append("-")
                    finally:
                        conn_check.close()
                else:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º "-" –¥–ª—è –≤—Å–µ—Ö
                    records_in_db_list = ["-"] * len(files_df)
                
                # –°–æ–∑–¥–∞–µ–º display_df —Å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
                display_df = pd.DataFrame()
                display_df['File Name'] = files_df['name']
                display_df['Size (MB)'] = files_df['size_mb'].round(2)
                display_df['Records in File'] = files_df['records']
                display_df['Records in DB'] = records_in_db_list
                display_df['Modified'] = files_df['modified']
                
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    hide_index=True,
                    height=300,
                    key='access_fees_files_df'
                )
            else:
                st.info("üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", icon="üìÅ")
        
        with col2:
            st.markdown("### –î–µ–π—Å—Ç–≤–∏—è")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
            uploaded_file = st.file_uploader(
                "Upload Access Fees file",
                type=['csv'],
                key='access_fees_upload'
            )
            
            if uploaded_file:
                save_path = STECCOM_DIR / uploaded_file.name
                if save_path.exists():
                    st.warning(f"‚ö†Ô∏è –§–∞–π–ª `{uploaded_file.name}` —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                else:
                    if st.button("üíæ Save File", key='save_access_fees'):
                        try:
                            STECCOM_DIR.mkdir(parents=True, exist_ok=True)
                            with open(save_path, 'wb') as f:
                                f.write(uploaded_file.getbuffer())
                            st.success(f"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {uploaded_file.name}")
                            st.rerun()
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            
            st.markdown("---")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
            already_loaded = []
            new_files = []
            orphaned_logs = []  # –§–∞–π–ª—ã —Å –∑–∞–ø–∏—Å—å—é –≤ load_logs, –Ω–æ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ
            files_to_reload = []  # –§–∞–π–ª—ã, –≥–¥–µ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ –º–µ–Ω—å—à–µ, —á–µ–º –≤ —Ñ–∞–π–ª–µ
            if access_fees_files:
                conn = get_db_connection()
                if conn:
                    try:
                        for file_info in access_fees_files:
                            file_name = file_info['name']
                            records_in_file = file_info.get('records')  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ
                            has_log_entry = False
                            has_data = False
                            records_in_db = 0
                            
                            # Oracle - –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
                            cursor = conn.cursor()
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–æ–π —Å—Ç–æ–ª–±–µ—Ü –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
                            try:
                                test_query = "SELECT FILE_NAME FROM LOAD_LOGS WHERE ROWNUM = 1"
                                cursor.execute(test_query)
                                file_col = "FILE_NAME"
                            except:
                                try:
                                    test_query = "SELECT SOURCE_FILE FROM LOAD_LOGS WHERE ROWNUM = 1"
                                    cursor.execute(test_query)
                                    file_col = "SOURCE_FILE"
                                except:
                                    file_col = "FILE_NAME"  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º load_logs
                            cursor.execute(f"""
                                SELECT COUNT(*) FROM LOAD_LOGS 
                                WHERE UPPER({file_col}) = UPPER(:1) 
                                AND UPPER(TABLE_NAME) = 'STECCOM_EXPENSES'
                                AND LOAD_STATUS = 'SUCCESS'
                            """, (file_name,))
                            has_log_entry = cursor.fetchone()[0] > 0
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                            cursor.execute("""
                                SELECT COUNT(*) FROM STECCOM_EXPENSES 
                                WHERE UPPER(SOURCE_FILE) = UPPER(:1)
                            """, (file_name,))
                            records_in_db = cursor.fetchone()[0]
                            has_data = records_in_db > 0
                            cursor.close()
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π
                            if has_log_entry and has_data:
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –∑–∞–ø–∏—Å–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
                                if records_in_file is not None and records_in_file > 0:
                                    if records_in_db < records_in_file:
                                        # –í –±–∞–∑–µ –º–µ–Ω—å—à–µ –∑–∞–ø–∏—Å–µ–π, —á–µ–º –≤ —Ñ–∞–π–ª–µ - –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å
                                        files_to_reload.append((file_name, records_in_file, records_in_db))
                                        new_files.append(file_name)
                                    else:
                                        # –í—Å–µ –∑–∞–ø–∏—Å–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
                                        already_loaded.append(file_name)
                                else:
                                    # –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Å—á–∏—Ç–∞—Ç—å –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª–µ, –Ω–æ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å - —Å—á–∏—Ç–∞–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º
                                    already_loaded.append(file_name)
                            elif has_log_entry and not has_data:
                                # –û—à–∏–±–æ—á–Ω–∞—è –∑–∞–ø–∏—Å—å –≤ load_logs –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ
                                orphaned_logs.append(file_name)
                                new_files.append(file_name)  # –†–∞–∑—Ä–µ—à–∞–µ–º –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫—É
                            else:
                                new_files.append(file_name)
                    except Exception as e:
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {e}")
                    finally:
                        conn.close()
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—É—Å–µ —Ñ–∞–π–ª–æ–≤
            if orphaned_logs:
                st.error(f"‚ö†Ô∏è **–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è:** {len(orphaned_logs)} —Ñ–∞–π–ª(–æ–≤) –∏–º–µ—é—Ç –∑–∞–ø–∏—Å—å –≤ –ª–æ–≥–∞—Ö, –Ω–æ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ –Ω–µ—Ç:")
                for orphan in orphaned_logs[:5]:
                    st.text(f"  - {orphan}")
                if len(orphaned_logs) > 5:
                    st.caption(f"  ... –∏ –µ—â–µ {len(orphaned_logs) - 5} —Ñ–∞–π–ª(–æ–≤)")
                st.info("üí° –≠—Ç–∏ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞–Ω–æ–≤–æ, —á—Ç–æ–±—ã –∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ.")
            
            if files_to_reload:
                st.warning(f"‚ö†Ô∏è **–ù–µ–ø–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞:** {len(files_to_reload)} —Ñ–∞–π–ª(–æ–≤) –∏–º–µ—é—Ç –º–µ–Ω—å—à–µ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ, —á–µ–º –≤ —Ñ–∞–π–ª–µ:")
                for file_name, in_file, in_db in files_to_reload[:5]:
                    st.text(f"  - {file_name}: {in_file:,} –≤ —Ñ–∞–π–ª–µ ‚Üí {in_db:,} –≤ –±–∞–∑–µ (–Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç {in_file - in_db:,})")
                if len(files_to_reload) > 5:
                    st.caption(f"  ... –∏ –µ—â–µ {len(files_to_reload) - 5} —Ñ–∞–π–ª(–æ–≤)")
                st.info("üí° –≠—Ç–∏ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞–Ω–æ–≤–æ, —á—Ç–æ–±—ã –¥–æ–ø–æ–ª–Ω–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–∞–ø–∏—Å–∏.")
            
            if already_loaded:
                if len(already_loaded) == len(access_fees_files) and not orphaned_logs and not files_to_reload:
                    st.success(f"‚úÖ **–í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é!** –ó–∞–≥—Ä—É–∂–∞—Ç—å –Ω–µ—á–µ–≥–æ.")
                    st.info(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(already_loaded)}")
                else:
                    st.info(f"‚úÖ {len(already_loaded)} –∏–∑ {len(access_fees_files)} —Ñ–∞–π–ª(–æ–≤) –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã:\n- " + "\n- ".join(already_loaded[:5]))
                    if len(already_loaded) > 5:
                        st.caption(f"... –∏ –µ—â–µ {len(already_loaded) - 5} —Ñ–∞–π–ª(–æ–≤)")
                    if new_files:
                        st.info(f"üì• –ë—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–æ–≤—ã—Ö/–Ω–µ–ø–æ–ª–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(new_files)}")
            
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
        st.markdown("---")
        st.subheader("üìä –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –≤ –±–∞–∑—É —Ñ–∞–π–ª—ã")
        loaded_access_fees = get_loaded_files_info('STECCOM_EXPENSES', 'SOURCE_FILE')
        if not loaded_access_fees.empty:
            loaded_access_fees.columns = ['File Name', 'Last Load Date', 'Records Count']
            st.dataframe(loaded_access_fees, use_container_width=True, hide_index=True)
        else:
            st.info("–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö")
    
    # ========== Load History Tab ==========
    with tab3:
        st.subheader("üìã –ò—Å—Ç–æ—Ä–∏—è –∑–∞–≥—Ä—É–∑–æ–∫")
        
        conn = get_db_connection()
        if conn:
            try:
                # –ò—Å—Ç–æ—Ä–∏—è –∏–∑ load_logs (Oracle)
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
                test_cursor = conn.cursor()
                try:
                    test_query = "SELECT FILE_NAME FROM LOAD_LOGS WHERE ROWNUM = 1"
                    test_cursor.execute(test_query)
                    file_col = "FILE_NAME"
                except:
                    try:
                        test_query = "SELECT SOURCE_FILE FROM LOAD_LOGS WHERE ROWNUM = 1"
                        test_cursor.execute(test_query)
                        file_col = "SOURCE_FILE"
                    except:
                        file_col = "FILE_NAME"  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                test_cursor.close()
                
                query = f"""
                SELECT 
                    TABLE_NAME,
                    {file_col} AS FILE_NAME,
                    LOAD_START_TIME,
                    RECORDS_LOADED,
                    LOAD_STATUS,
                    ERROR_MESSAGE
                FROM LOAD_LOGS
                ORDER BY LOAD_START_TIME DESC
                FETCH FIRST 50 ROWS ONLY
                """
                history_df = pd.read_sql(query, conn)
                
                if not history_df.empty:
                    history_df.columns = ['Table Name', 'File Name', 'Load Date', 'Records Count', 'Status', 'Error Message']
                    history_df['Load Date'] = pd.to_datetime(history_df['Load Date']).dt.strftime('%Y-%m-%d %H:%M:%S')
                    st.dataframe(history_df, use_container_width=True, hide_index=True)
                else:
                    st.info("–ò—Å—Ç–æ—Ä–∏—è –∑–∞–≥—Ä—É–∑–æ–∫ –ø—É—Å—Ç–∞")
            except Exception as e:
                st.warning(f"–¢–∞–±–ª–∏—Ü–∞ LOAD_LOGS –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
            finally:
                conn.close()


if __name__ == "__main__":
    main()

