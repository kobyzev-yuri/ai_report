#!/usr/bin/env python3
"""
Streamlit –æ—Ç—á–µ—Ç –ø–æ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—é —Ç—Ä–∞—Ñ–∏–∫–∞ Iridium M2M
–†–∞—Å—á–µ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è SBD-1 –∏ SBD-10
"""

import streamlit as st
import pandas as pd
import psycopg2
from datetime import datetime
import io
import os
from pathlib import Path

# –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å config.env –µ—Å–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
def load_config_env():
    """–ó–∞–≥—Ä—É–∑–∫–∞ config.env –µ—Å–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"""
    if not os.getenv('POSTGRES_PASSWORD'):
        config_file = Path(__file__).parent / 'config.env'
        if config_file.exists():
            with open(config_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip().strip('"\'')
                        if key.startswith('POSTGRES_') and not os.getenv(key):
                            os.environ[key] = value

# –ó–∞–≥—Ä—É–∂–∞–µ–º config.env –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
load_config_env()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
# –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ config.env —á–µ—Ä–µ–∑ run_streamlit.sh –∏–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ config.env
DB_CONFIG = {
    'dbname': os.getenv('POSTGRES_DB', 'billing'),
    'user': os.getenv('POSTGRES_USER', 'cnn'),
    'password': os.getenv('POSTGRES_PASSWORD', ''),
    'host': os.getenv('POSTGRES_HOST', 'localhost'),
    'port': int(os.getenv('POSTGRES_PORT', '5432'))
}


def get_connection():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        if not DB_CONFIG['password']:
            st.error("‚ö†Ô∏è –ü–∞—Ä–æ–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ config.env –∑–∞–≥—Ä—É–∂–µ–Ω —á–µ—Ä–µ–∑ run_streamlit.sh")
            return None
        conn = psycopg2.connect(**DB_CONFIG)
        return conn
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        st.info(f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {DB_CONFIG['user']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}")
        return None


def count_file_records(file_path):
    """–ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ (CSV –∏–ª–∏ XLSX)"""
    try:
        file_ext = Path(file_path).suffix.lower()
        
        if not Path(file_path).exists():
            return None
        
        if file_ext == '.xlsx':
            try:
                df = pd.read_excel(file_path, dtype=str, na_filter=False, engine='openpyxl')
                df = df.dropna(how='all')
                df = df[~df.apply(lambda x: x.astype(str).str.strip().eq('').all(), axis=1)]
                return len(df)
            except Exception as e:
                try:
                    df = pd.read_excel(file_path, dtype=str, na_filter=False)
                    df = df.dropna(how='all')
                    return len(df)
                except:
                    return None
        else:
            # CSV —Ñ–∞–π–ª
            try:
                df = pd.read_csv(file_path, dtype=str, na_filter=False)
                return len(df)
            except Exception as e:
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                for encoding in ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']:
                    try:
                        df = pd.read_csv(file_path, dtype=str, na_filter=False, encoding=encoding)
                        return len(df)
                    except:
                        continue
                return None
    except Exception as e:
        return None


def get_records_in_db(file_name, table_name='spnet_traffic'):
    """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ –¥–ª—è —Ñ–∞–π–ª–∞"""
    conn = get_connection()
    if not conn:
        return None
    try:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT COUNT(*) FROM {} 
            WHERE LOWER(source_file) = LOWER(%s)
        """.format(table_name), (file_name,))
        count = cursor.fetchone()[0]
        cursor.close()
        return count
    except Exception as e:
        return None
    finally:
        conn.close()


def get_main_report(period_filter=None, plan_filter=None):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    conn = get_connection()
    if not conn:
        return None
    
    # –§–∏–ª—å—Ç—Ä –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º
    period_condition = ""
    if period_filter and period_filter != "All Periods":
        # bill_month –≤ PostgreSQL —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM" (—Ç–µ–∫—Å—Ç)
        period_condition = f"AND v.bill_month = '{period_filter}'"
    
    # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∞—Ä–∏—Ñ–∞–º (–≤—Å–µ —Ç–∞—Ä–∏—Ñ—ã)
    plan_condition = ""
    if plan_filter and plan_filter != "All Plans":
        plan_condition = f"AND v.plan_name = '{plan_filter}'"
    
    query = f"""
    SELECT 
        v.bill_month AS "Bill Month",
        v.imei AS "IMEI",
        v.contract_id AS "Contract ID",
        -- –î–æ–ø. –ø–æ–ª—è –∏–∑ –±–∏–ª–ª–∏–Ω–≥–∞ (–ø–æ—Å–ª–µ Contract ID)
        v.display_name         AS "Organization/Person",
        v.code_1c              AS "Code 1C",
        v.service_id           AS "Service ID",
        v.agreement_number     AS "Agreement #",
        COALESCE(v.steccom_plan_name_monthly, '') AS "Plan Monthly",
        COALESCE(v.steccom_plan_name_suspended, '') AS "Plan Suspended",
        -- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–∞—Ñ–∏–∫–∞ –∏ —Å–æ–±—ã—Ç–∏–π
        ROUND(CAST(v.traffic_usage_bytes AS NUMERIC) / 1000, 2) AS "Traffic Usage (KB)",
        v.events_count AS "Events (Count)",
        v.data_usage_events AS "Data Events",
        v.mailbox_events AS "Mailbox Events",
        v.registration_events AS "Registration Events",
        -- –ü—Ä–µ–≤—ã—à–µ–Ω–∏—è: –∑–∞–Ω—É–ª—è–µ–º —Å—É–º–º—ã Iridium –¥–ª—è –°–¢–≠–ö.–ö–û–ú
        CASE 
            WHEN UPPER(COALESCE(v.display_name, '')) LIKE '%–°–¢–≠–ö.–ö–û–ú%' 
                 OR UPPER(COALESCE(v.display_name, '')) LIKE '%–°–¢–≠–ö–ö–û–ú%'
                 OR UPPER(COALESCE(v.display_name, '')) LIKE '%STECCOM%'
            THEN 0
            ELSE v.overage_kb
        END AS "Overage (KB)",
        CASE 
            WHEN UPPER(COALESCE(v.display_name, '')) LIKE '%–°–¢–≠–ö.–ö–û–ú%' 
                 OR UPPER(COALESCE(v.display_name, '')) LIKE '%–°–¢–≠–ö–ö–û–ú%'
                 OR UPPER(COALESCE(v.display_name, '')) LIKE '%STECCOM%'
            THEN 0
            ELSE v.calculated_overage
        END AS "Calculated Overage ($)",
        CASE 
            WHEN UPPER(COALESCE(v.display_name, '')) LIKE '%–°–¢–≠–ö.–ö–û–ú%' 
                 OR UPPER(COALESCE(v.display_name, '')) LIKE '%–°–¢–≠–ö–ö–û–ú%'
                 OR UPPER(COALESCE(v.display_name, '')) LIKE '%STECCOM%'
            THEN 0
            ELSE v.spnet_total_amount
        END AS "SPNet Total Amount ($)",
        -- Fees –∏–∑ STECCOM_EXPENSES (—É–±—Ä–∞–ª–∏ –ø—Ä–µ—Ñ–∏–∫—Å "Fee:")
        COALESCE(v.fee_activation_fee, 0) AS "Activation Fee",
        COALESCE(v.fee_advance_charge, 0) AS "Advance Charge",
        COALESCE(v.fee_credit, 0) AS "Credit",
        COALESCE(v.fee_credited, 0) AS "Credited",
        COALESCE(v.fee_prorated, 0) AS "Prorated"
    FROM v_consolidated_report_with_billing v
    WHERE 1=1
        {plan_condition}
        {period_condition}
    ORDER BY v.bill_month DESC, "Calculated Overage ($)" DESC NULLS LAST
    """
    
    try:
        df = pd.read_sql_query(query, conn)
        
        if df.empty:
            return df
        
        # Fees —É–∂–µ –≤ VIEW, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è
        # Bill Month —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM" (—Ç–µ–∫—Å—Ç), –Ω–µ –Ω—É–∂–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å
        if 'Bill Month' in df.columns:
            df['Bill Month'] = df['Bill Month'].astype(str).replace('nan', '')
        
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
        return None
    finally:
        conn.close()


@st.cache_data(ttl=300)  # –ö—ç—à–∏—Ä—É–µ–º –Ω–∞ 5 –º–∏–Ω—É—Ç
def get_periods():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø–µ—Ä–∏–æ–¥–æ–≤"""
    conn = get_connection()
    if not conn:
        return []
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º v_consolidated_report_with_billing, –≥–¥–µ bill_month —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM"
    query = """
    SELECT DISTINCT bill_month
    FROM v_consolidated_report_with_billing
    WHERE bill_month IS NOT NULL
    ORDER BY bill_month DESC
    """
    
    try:
        cursor = conn.cursor()
        cursor.execute(query)
        periods = []
        for row in cursor.fetchall():
            if row[0]:
                # bill_month —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM"
                periods.append(str(row[0]))
        return periods
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–∏–æ–¥–æ–≤: {e}")
        return []
    finally:
        conn.close()


@st.cache_data(ttl=300)  # –ö—ç—à–∏—Ä—É–µ–º –Ω–∞ 5 –º–∏–Ω—É—Ç
def get_plans():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–∞—Ä–∏—Ñ–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤"""
    conn = get_connection()
    if not conn:
        return []
    
    query = """
    SELECT DISTINCT plan_name
    FROM v_consolidated_report_with_billing
    WHERE plan_name IS NOT NULL
    ORDER BY plan_name
    """
    
    try:
        cursor = conn.cursor()
        cursor.execute(query)
        plans = [row[0] for row in cursor.fetchall() if row[0]]
        return plans
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–ª–∞–Ω–æ–≤: {e}")
        return []
    finally:
        conn.close()


def export_to_csv(df):
    """–≠–∫—Å–ø–æ—Ä—Ç –≤ CSV"""
    output = io.StringIO()
    df.to_csv(output, index=False, encoding='utf-8')
    return output.getvalue()


def export_to_excel(df):
    """–≠–∫—Å–ø–æ—Ä—Ç –≤ Excel"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Overage Report')
    return output.getvalue()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    st.set_page_config(
        page_title="Iridium M2M Overage Report (SBD-1, SBD-10)",
        page_icon="üìä",
        layout="wide"
    )
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if not DB_CONFIG.get('password'):
        st.error("‚ö†Ô∏è **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!**")
        st.warning("""
        –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç:
        ```bash
        ./run_streamlit.sh
        ```
        
        –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç `config.env` —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
        """)
        st.stop()
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üìä Iridium M2M Overage Report")
    st.markdown("**All Plans (Calculated Overage for SBD-1 and SBD-10 only)**")
    st.markdown("---")
    
    # –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏ –¥–ª—è –æ—Ç—á–µ—Ç–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    # –§–∏–ª—å—Ç—Ä—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ (–≤–Ω–µ –≤–∫–ª–∞–¥–æ–∫, —á—Ç–æ–±—ã –±—ã–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –≤—Å–µ–≥–¥–∞)
    with st.sidebar:
        st.header("‚öôÔ∏è Filters")
        
        # –ü–µ—Ä–∏–æ–¥
        periods = get_periods()
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥ (–ø–µ—Ä–≤—ã–π –≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Å–ø–∏—Å–∫–µ)
        if 'selected_period_index' not in st.session_state:
            st.session_state.selected_period_index = 0  # 0 = –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥ (–Ω–µ "All Periods")
        
        period_options = periods + ["All Periods"]  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥ –ø–µ—Ä–≤—ã–º, –ø–æ—Ç–æ–º "All Periods"
        selected_period = st.selectbox(
            "Period", 
            period_options,
            index=st.session_state.selected_period_index,
            key='period_selectbox'
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏
        if selected_period in period_options:
            st.session_state.selected_period_index = period_options.index(selected_period)
        
        # –¢–∞—Ä–∏—Ñ–Ω—ã–π –ø–ª–∞–Ω
        plans = get_plans()
        plan_options = ["All Plans"] + plans
        selected_plan = st.selectbox("Plan", plan_options, key='plan_selectbox')
        
        st.markdown("---")
        st.header("üîê Database Connection")
        st.caption(f"üì° {DB_CONFIG['user']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}")
        
        # –ö–Ω–æ–ø–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        if st.button("üîå Test Connection", key='test_connection_btn'):
            test_conn = get_connection()
            if test_conn:
                st.success("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!")
                test_conn.close()
            else:
                st.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ config.env")
        
        st.info("üí° –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ config.env –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —á–µ—Ä–µ–∑ run_streamlit.sh")
    
    tab_report, tab_loader = st.tabs(["üìä Report", "üì• Data Loader"])
    
    # ========== REPORT TAB ==========
    with tab_report:
        
        period_filter = None if selected_period == "All Periods" else selected_period
        plan_filter = None if selected_plan == "All Plans" else selected_plan
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ç—á–µ—Ç –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω –ø–µ—Ä–∏–æ–¥ (–Ω–µ "All Periods")
        filter_key = f"{period_filter}_{plan_filter}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å –æ—Ç—á–µ—Ç
        if period_filter is not None:
            if 'last_report_key' not in st.session_state or st.session_state.last_report_key != filter_key:
                with st.spinner("Loading report data..."):
                    df = get_main_report(period_filter, plan_filter)
                    st.session_state.last_report_key = filter_key
                    st.session_state.last_report_df = df
            else:
                df = st.session_state.last_report_df
        else:
            # –ï—Å–ª–∏ –ø–µ—Ä–∏–æ–¥ –Ω–µ –≤—ã–±—Ä–∞–Ω, –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –æ—Ç—á–µ—Ç
            df = None
            st.info("‚ÑπÔ∏è –í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç—á–µ—Ç–∞")
        
        if df is not None and not df.empty:
            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df):,}")
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            col1, col2 = st.columns(2)
            with col1:
                st.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", f"{len(df):,}")
            with col2:
                total_overage = df["Calculated Overage ($)"].sum()
                st.metric("Total Overage", f"${total_overage:,.2f}")
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –≤–∏–¥–Ω—ã, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ NULL
            display_df = df.copy()
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º NULL –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏ –¥–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            for col in display_df.columns:
                if display_df[col].dtype == 'object':  # —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                    display_df[col] = display_df[col].fillna('')
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ Code 1C –≤—Å–µ–≥–¥–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ pandas —Å–∫—Ä—ã–ª –µ—ë)
            if 'Code 1C' in df.columns:
                # –ö–æ–ª–æ–Ω–∫–∞ –µ—Å—Ç—å, –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–æ–ª–Ω—è–µ–º NULL
                display_df['Code 1C'] = display_df['Code 1C'].fillna('')
            else:
                # –ö–æ–ª–æ–Ω–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º (–Ω–µ –¥–æ–ª–∂–Ω–æ —Å–ª—É—á–∏—Ç—å—Å—è, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
                display_df['Code 1C'] = ''
            
            # –¢–∞–±–ª–∏—Ü–∞
            st.dataframe(
                display_df,
                use_container_width=True,
                hide_index=True,
                height=600
            )
            
            # –≠–∫—Å–ø–æ—Ä—Ç
            st.markdown("---")
            st.subheader("üíæ Export")
            
            col1, col2 = st.columns(2)
            
            with col1:
                csv_data = export_to_csv(df)
                st.download_button(
                    label="üì• Download CSV",
                    data=csv_data,
                    file_name=f"iridium_overage_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            with col2:
                try:
                    excel_data = export_to_excel(df)
                    st.download_button(
                        label="üì• Download Excel",
                        data=excel_data,
                        file_name=f"iridium_overage_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
                except Exception as e:
                    st.warning(f"Excel export unavailable: {e}")

            # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (30-–¥–Ω–µ–≤–Ω—ã–µ —Ü–∏–∫–ª—ã —Å–æ 2-–≥–æ –ø–æ 2-–µ)
            st.markdown("---")
            st.subheader("üîé Fees breakdown (by category)")
            contract_filter = st.text_input("Filter by Contract ID (optional)", value="")

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            contract_ids = df['Contract ID'].dropna().unique().tolist() if not df.empty else []
            
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ñ–∏–ª—å—Ç—Ä, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
            if contract_filter.strip():
                contract_ids.append(contract_filter.strip())
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –ë–ï–ó —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –≤—Å–µ–º –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞–º, –µ—Å–ª–∏ –∏—Ö —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            conn2 = get_connection()
            if conn2:
                contract_condition = ""
                
                if contract_ids:
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ (–º–∞–∫—Å 200)
                    limited_contract_ids = contract_ids[:200]
                    
                    # –ï—Å–ª–∏ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ –º–Ω–æ–≥–æ (>100), –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                    if len(contract_ids) > 100:
                        try:
                            cursor = conn2.cursor()
                            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                            cursor.execute("DROP TABLE IF EXISTS temp_contract_filter")
                            cursor.execute("CREATE TEMP TABLE temp_contract_filter (contract_id TEXT)")
                            
                            # –í—Å—Ç–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ executemany
                            insert_data = [(str(c),) for c in limited_contract_ids]
                            cursor.executemany(
                                "INSERT INTO temp_contract_filter VALUES (%s)",
                                insert_data
                            )
                            conn2.commit()
                            cursor.close()
                            
                            contract_condition = "AND f.contract_id IN (SELECT contract_id FROM temp_contract_filter)"
                        except Exception as e:
                            st.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —É—Å–ª–æ–≤–∏–µ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ 100 –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞–º–∏).")
                            # Fallback –Ω–∞ –ø—Ä—è–º–æ–µ —É—Å–ª–æ–≤–∏–µ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ)
                            contract_list = "', '".join([str(c).replace("'", "''") for c in limited_contract_ids[:100]])
                            contract_condition = f"AND f.contract_id IN ('{contract_list}')"
                    else:
                        # –ï—Å–ª–∏ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ –Ω–µ–º–Ω–æ–≥–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π IN (—ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫–∞–≤—ã—á–∫–∏)
                        contract_list = "', '".join([str(c).replace("'", "''") for c in contract_ids])
                        contract_condition = f"AND f.contract_id IN ('{contract_list}')"
                
                # –§–∏–ª—å—Ç—Ä –ø–æ –ø–µ—Ä–∏–æ–¥—É (–µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω –ø–µ—Ä–∏–æ–¥ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –æ—Ç—á–µ—Ç–µ)
                period_condition = ""
                if period_filter and period_filter != "All Periods":
                    year, month = period_filter.split('-')
                    # –ò—â–µ–º fees —Å –ø–µ—Ä–∏–æ–¥–∞–º–∏ –±–ª–∏–∑–∫–∏–º–∏ –∫ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –º–µ—Å—è—Ü—É (—Ñ–æ—Ä–º–∞—Ç YYYYMMDD)
                    # –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è 2025-05 –∏—â–µ–º –ø–µ—Ä–∏–æ–¥—ã –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å 202505 –∏–ª–∏ 202506
                    period_pattern = f"{year}{month:0>2}"
                    period_condition = f"AND f.fee_period_date::text LIKE '{period_pattern}%'"

                fees_q = f"""
                SELECT 
                    f.fee_period_date AS "Period",
                    f.contract_id AS "Contract ID",
                    f.imei AS "IMEI",
                    f.category AS "Category", 
                    SUM(f.amount) AS "Amount"
                FROM v_steccom_access_fees_norm f
                WHERE f.imei IS NOT NULL
                {contract_condition}
                {period_condition}
                GROUP BY f.fee_period_date, f.contract_id, f.imei, f.category
                ORDER BY f.fee_period_date DESC, f.contract_id, f.imei, f.category
                """
                try:
                    fees_detail_df = pd.read_sql_query(fees_q, conn2)
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–µ—Ä–∏–æ–¥: 20250302 -> "2025-03-02"
                    if 'Period' in fees_detail_df.columns and not fees_detail_df.empty:
                        fees_detail_df['Period'] = fees_detail_df['Period'].apply(
                            lambda x: f"{str(x)[:4]}-{str(x)[4:6]}-{str(x)[6:8]}" if pd.notna(x) and len(str(x)) >= 8 else str(x)
                        )
                    
                    if not fees_detail_df.empty:
                        st.dataframe(fees_detail_df, use_container_width=True, hide_index=True, height=300)
                    else:
                        st.info("No fees data found for selected filters")
                except Exception as e:
                    st.warning(f"Failed to load fees breakdown: {e}")
                finally:
                    conn2.close()
        
        elif df is not None and df.empty:
            st.warning("‚ö†Ô∏è No data found with selected filters")
        else:
            st.error("‚ùå Error loading data")
    
    # ========== DATA LOADER TAB ==========
    with tab_loader:
        st.header("üì• Data Loader")
        st.markdown("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –ò—Ä–∏–¥–∏—É–º (—Ç—Ä–∞—Ñ–∏–∫ –∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ñ–∞–π–ª—ã)")
        st.markdown("---")
        
        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
        from pathlib import Path
        DATA_DIR = Path(__file__).parent / 'data'
        SPNET_DIR = DATA_DIR / 'SPNet reports'
        ACCESS_FEES_DIR = DATA_DIR / 'STECCOMLLCRussiaSBD.AccessFees_reports'
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ –ø–æ –∏–º–µ–Ω–∏
        def detect_file_type(filename):
            """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞ (SPNet –∏–ª–∏ STECCOM) –ø–æ –∏–º–µ–Ω–∏"""
            filename_lower = filename.lower()
            if 'spnet' in filename_lower or 'traffic' in filename_lower:
                return 'SPNet'
            elif 'steccom' in filename_lower or 'access' in filename_lower or 'fee' in filename_lower:
                return 'STECCOM'
            return None
        
        st.markdown("---")
        
        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ —Ñ–∞–π–ª–æ–≤ - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –ø–æ –∏–º–µ–Ω–∏
        st.subheader("üì§ Upload File")
        uploaded_file = st.file_uploader(
            "üì§ Upload file (drag & drop) - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç —Ç–∏–ø –ø–æ –∏–º–µ–Ω–∏",
            type=['csv', 'xlsx'],
            key='file_uploader',
            help="–§–∞–π–ª—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –Ω—É–∂–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"
        )
        
        if uploaded_file:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
            file_type = detect_file_type(uploaded_file.name)
            
            if file_type == 'SPNet':
                target_dir = SPNET_DIR
                file_type_msg = "‚úÖ **–û–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ SPNet —Ñ–∞–π–ª** - –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ SPNet reports"
            elif file_type == 'STECCOM':
                target_dir = ACCESS_FEES_DIR
                file_type_msg = "‚úÖ **–û–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ Access Fees —Ñ–∞–π–ª** - –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ Access Fees directory"
            else:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                file_type = st.radio(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Ñ–∞–π–ª–∞. –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø:",
                    ["SPNet Traffic", "Access Fees (Financial)"],
                    horizontal=True,
                    key='file_type_selector'
                )
                if file_type == "SPNet Traffic":
                    target_dir = SPNET_DIR
                    file_type_msg = "‚ö†Ô∏è **–í—ã–±—Ä–∞–Ω SPNet** - –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ SPNet reports"
                else:
                    target_dir = ACCESS_FEES_DIR
                    file_type_msg = "‚ö†Ô∏è **–í—ã–±—Ä–∞–Ω Access Fees** - –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ Access Fees directory"
            
            if file_type:
                st.info(file_type_msg)
                save_path = target_dir / uploaded_file.name
                
                if save_path.exists():
                    st.warning(f"‚ö†Ô∏è File `{uploaded_file.name}` already exists")
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º form –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                    with st.form(key='save_file_form', clear_on_submit=True):
                        if st.form_submit_button("üíæ Save File", use_container_width=True):
                            try:
                                with st.spinner("Saving file..."):
                                    target_dir.mkdir(parents=True, exist_ok=True)
                                    with open(save_path, 'wb') as f:
                                        f.write(uploaded_file.getbuffer())
                                st.success(f"‚úÖ File saved to {target_dir.name}/: {uploaded_file.name}")
                            except Exception as e:
                                st.error(f"Error saving: {e}")
        
        st.markdown("---")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±–∞ —Ç–∏–ø–∞ —Ñ–∞–π–ª–æ–≤ –≤ –¥–≤—É—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìä SPNet Traffic Reports")
            st.markdown(f"**Directory:** `{SPNET_DIR}`")
            
            # –°–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ —Å —Å—Ç–∞—Ç—É—Å–æ–º –∑–∞–≥—Ä—É–∑–∫–∏
            if SPNET_DIR.exists():
                spnet_files = list(SPNET_DIR.glob("*.csv")) + list(SPNET_DIR.glob("*.xlsx"))
                if spnet_files:
                    # –ö—ç—à–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∞—Ç—å –∑–∞–ø—Ä–æ—Å –ø—Ä–∏ –∫–∞–∂–¥–æ–º rerun
                    cache_key = 'spnet_loaded_files'
                    if cache_key not in st.session_state:
                        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ load_logs —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑
                        conn_status = get_connection()
                        loaded_files = set()
                        if conn_status:
                            try:
                                cursor = conn_status.cursor()
                                cursor.execute("""
                                    SELECT LOWER(source_file) FROM load_logs 
                                    WHERE LOWER(table_name) = LOWER('spnet_traffic') 
                                    AND load_status = 'SUCCESS'
                                """)
                                loaded_files = {row[0] for row in cursor.fetchall()}
                                cursor.close()
                                st.session_state[cache_key] = loaded_files
                            except:
                                st.session_state[cache_key] = set()
                            finally:
                                conn_status.close()
                        else:
                            st.session_state[cache_key] = set()
                    else:
                        loaded_files = st.session_state[cache_key]
                    
                    st.markdown(f"**Found files: {len(spnet_files)}**")
                    files_info = []
                    for f in sorted(spnet_files, key=lambda x: x.stat().st_mtime, reverse=True)[:10]:
                        is_loaded = f.name.lower() in loaded_files
                        
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª–µ
                        records_in_file = count_file_records(f)
                        records_in_file_str = f"{records_in_file:,}" if records_in_file is not None else "N/A"
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ
                        records_in_db = None
                        if is_loaded:
                            records_in_db = get_records_in_db(f.name, 'spnet_traffic')
                        records_in_db_str = f"{records_in_db:,}" if records_in_db is not None and records_in_db > 0 else "-"
                        
                        files_info.append({
                            'File Name': f.name,
                            'Size (MB)': round(f.stat().st_size / (1024 * 1024), 2),
                            'Records in File': records_in_file_str,
                            'Records in DB': records_in_db_str,
                            'Modified': datetime.fromtimestamp(f.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                            'Status': '‚úÖ Loaded' if is_loaded else '‚è≥ Not loaded'
                        })
                    df_files = pd.DataFrame(files_info)
                    st.dataframe(df_files, use_container_width=True, hide_index=True, height=200)
                    
                    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                    if st.button("üîÑ Refresh Load Status", key='refresh_spnet_status'):
                        if cache_key in st.session_state:
                            del st.session_state[cache_key]
                        st.rerun()
                else:
                    st.info("üìÅ Directory is empty")
            else:
                st.info(f"üìÅ Directory does not exist: {SPNET_DIR}")
        
        with col2:
            st.subheader("üí∞ Access Fees (Financial)")
            st.markdown(f"**Directory:** `{ACCESS_FEES_DIR}`")
            
            # –°–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ —Å —Å—Ç–∞—Ç—É—Å–æ–º –∑–∞–≥—Ä—É–∑–∫–∏
            if ACCESS_FEES_DIR.exists():
                steccom_files = list(ACCESS_FEES_DIR.glob("*.csv"))
                if steccom_files:
                    # –ö—ç—à–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∞—Ç—å –∑–∞–ø—Ä–æ—Å –ø—Ä–∏ –∫–∞–∂–¥–æ–º rerun
                    cache_key = 'steccom_loaded_files'
                    if cache_key not in st.session_state:
                        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ load_logs —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑
                        conn_status = get_connection()
                        loaded_files = set()
                        if conn_status:
                            try:
                                cursor = conn_status.cursor()
                                cursor.execute("""
                                    SELECT LOWER(source_file) FROM load_logs 
                                    WHERE LOWER(table_name) = LOWER('steccom_expenses') 
                                    AND load_status = 'SUCCESS'
                                """)
                                loaded_files = {row[0] for row in cursor.fetchall()}
                                cursor.close()
                                st.session_state[cache_key] = loaded_files
                            except:
                                st.session_state[cache_key] = set()
                            finally:
                                conn_status.close()
                        else:
                            st.session_state[cache_key] = set()
                    else:
                        loaded_files = st.session_state[cache_key]
                    
                    st.markdown(f"**Found files: {len(steccom_files)}**")
                    files_info = []
                    for f in sorted(steccom_files, key=lambda x: x.stat().st_mtime, reverse=True)[:10]:
                        is_loaded = f.name.lower() in loaded_files
                        
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª–µ
                        records_in_file = count_file_records(f)
                        records_in_file_str = f"{records_in_file:,}" if records_in_file is not None else "N/A"
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ
                        records_in_db = None
                        if is_loaded:
                            records_in_db = get_records_in_db(f.name, 'steccom_expenses')
                        records_in_db_str = f"{records_in_db:,}" if records_in_db is not None and records_in_db > 0 else "-"
                        
                        files_info.append({
                            'File Name': f.name,
                            'Size (MB)': round(f.stat().st_size / (1024 * 1024), 2),
                            'Records in File': records_in_file_str,
                            'Records in DB': records_in_db_str,
                            'Modified': datetime.fromtimestamp(f.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                            'Status': '‚úÖ Loaded' if is_loaded else '‚è≥ Not loaded'
                        })
                    df_files = pd.DataFrame(files_info)
                    st.dataframe(df_files, use_container_width=True, hide_index=True, height=200)
                    
                    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                    if st.button("üîÑ Refresh Load Status", key='refresh_steccom_status'):
                        if cache_key in st.session_state:
                            del st.session_state[cache_key]
                        st.rerun()
                else:
                    st.info("üìÅ Directory is empty")
            else:
                st.info(f"üìÅ Directory does not exist: {ACCESS_FEES_DIR}")
        
        st.markdown("---")
        st.subheader("üîÑ Import to Database")
        
        # –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É - –æ–¥–Ω–∞ –∫–Ω–æ–ø–∫–∞ –¥–ª—è –æ–±–æ–∏—Ö —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤
        if st.button("üì• Import All Files", use_container_width=True, type="primary"):
            import io
            import sys
            all_logs = []
            
            # –ò–º–ø–æ—Ä—Ç SPNet
            with st.spinner("–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö SPNet –≤ PostgreSQL..."):
                try:
                    from python.load_data_postgres import PostgresDataLoader
                    
                    loader = PostgresDataLoader(DB_CONFIG)
                    if loader.connect():
                        loader.spnet_path = str(SPNET_DIR)
                        
                        log_capture = io.StringIO()
                        old_stdout = sys.stdout
                        old_stderr = sys.stderr
                        
                        try:
                            sys.stdout = log_capture
                            sys.stderr = log_capture
                            
                            result = loader.load_spnet_files()
                            log_output = log_capture.getvalue()
                            all_logs.append(("SPNet", result, log_output))
                        finally:
                            sys.stdout = old_stdout
                            sys.stderr = old_stderr
                            if loader.connection:
                                loader.close()
                    else:
                        all_logs.append(("SPNet", False, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"))
                except Exception as e:
                    import traceback
                    all_logs.append(("SPNet", False, f"‚ùå –û—à–∏–±–∫–∞: {e}\n{traceback.format_exc()}"))
            
            # –ò–º–ø–æ—Ä—Ç Access Fees
            with st.spinner("–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö Access Fees –≤ PostgreSQL..."):
                try:
                    from python.load_data_postgres import PostgresDataLoader
                    
                    loader = PostgresDataLoader(DB_CONFIG)
                    if loader.connect():
                        loader.steccom_path = str(ACCESS_FEES_DIR)
                        
                        log_capture = io.StringIO()
                        old_stdout = sys.stdout
                        old_stderr = sys.stderr
                        
                        try:
                            sys.stdout = log_capture
                            sys.stderr = log_capture
                            
                            result = loader.load_steccom_files()
                            log_output = log_capture.getvalue()
                            all_logs.append(("Access Fees", result, log_output))
                        finally:
                            sys.stdout = old_stdout
                            sys.stderr = old_stderr
                            if loader.connection:
                                loader.close()
                    else:
                        all_logs.append(("Access Fees", False, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"))
                except Exception as e:
                    import traceback
                    all_logs.append(("Access Fees", False, f"‚ùå –û—à–∏–±–∫–∞: {e}\n{traceback.format_exc()}"))
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for file_type, success, log_output in all_logs:
                if success:
                    st.success(f"‚úÖ –ò–º–ø–æ—Ä—Ç {file_type} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                else:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ {file_type}")
                if log_output:
                    st.text_area(f"{file_type} Log", log_output, height=150, key=f'log_{file_type.lower().replace(" ", "_")}')
        
        st.markdown("---")
        st.caption("üí° **Tip:** After importing, refresh the Report tab to see updated data")


if __name__ == "__main__":
    main()
